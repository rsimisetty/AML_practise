{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsimisetty/AML_practise/blob/main/Week4_Day7_Review_and_Feedback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4XusxB_wfed"
      },
      "source": [
        "# Week 4, Day 7: Review and Feedback Session\n",
        "\n",
        "## Session Overview\n",
        "This session will review the key concepts covered in Week 4 and provide practice exercises to reinforce learning:\n",
        "\n",
        "1. K-means Clustering\n",
        "2. Hierarchical Clustering\n",
        "3. Principal Component Analysis\n",
        "4. t-SNE and UMAP\n",
        "5. Anomaly Detection\n",
        "\n",
        "## Learning Objectives\n",
        "- Reinforce unsupervised learning concepts\n",
        "- Practice technique selection\n",
        "- Master implementation skills\n",
        "- Prepare for Week 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ny0o_GXewfef"
      },
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from umap import UMAP\n",
        "from sklearn.ensemble import IsolationForest"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13A36_JXwfeg"
      },
      "source": [
        "## 1. Clustering Review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEqUoGI3wfeg"
      },
      "source": [
        "def clustering_review():\n",
        "    # Generate synthetic data\n",
        "    np.random.seed(42)\n",
        "    n_samples = 300\n",
        "\n",
        "    # Create three distinct clusters\n",
        "    cluster1 = np.random.normal(0, 1, (n_samples, 2))\n",
        "    cluster2 = np.random.normal(5, 1, (n_samples, 2))\n",
        "    cluster3 = np.random.normal(2.5, 1, (n_samples, 2)) + np.array([0, 5])\n",
        "\n",
        "    # Combine clusters\n",
        "    X = np.vstack([cluster1, cluster2, cluster3])\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Apply different clustering methods\n",
        "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "    hierarchical = AgglomerativeClustering(n_clusters=3)\n",
        "\n",
        "    kmeans_labels = kmeans.fit_predict(X_scaled)\n",
        "    hierarchical_labels = hierarchical.fit_predict(X_scaled)\n",
        "\n",
        "    # Visualize results\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Original data\n",
        "    plt.subplot(131)\n",
        "    plt.scatter(X[:, 0], X[:, 1], alpha=0.5)\n",
        "    plt.title('Original Data')\n",
        "\n",
        "    # K-means\n",
        "    plt.subplot(132)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=kmeans_labels, cmap='viridis')\n",
        "    plt.title('K-means Clustering')\n",
        "\n",
        "    # Hierarchical\n",
        "    plt.subplot(133)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=hierarchical_labels, cmap='viridis')\n",
        "    plt.title('Hierarchical Clustering')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "clustering_review()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCX8HSZfwfeh"
      },
      "source": [
        "## 2. Dimensionality Reduction Review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA3LqSvqwfeh"
      },
      "source": [
        "def dimensionality_reduction_review():\n",
        "    # Generate high-dimensional data\n",
        "    np.random.seed(42)\n",
        "    n_samples = 1000\n",
        "    n_features = 50\n",
        "\n",
        "    # Create data with underlying structure\n",
        "    X = np.random.randn(n_samples, n_features)\n",
        "    # Add some correlation\n",
        "    X[:, 1] = X[:, 0] + np.random.randn(n_samples) * 0.1\n",
        "    X[:, 2] = X[:, 0] - X[:, 1] + np.random.randn(n_samples) * 0.1\n",
        "\n",
        "    # Apply different reduction methods\n",
        "    pca = PCA(n_components=2)\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    umap = UMAP(n_components=2, random_state=42)\n",
        "\n",
        "    X_pca = pca.fit_transform(X)\n",
        "    X_tsne = tsne.fit_transform(X)\n",
        "    X_umap = umap.fit_transform(X)\n",
        "\n",
        "    # Visualize results\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # PCA\n",
        "    plt.subplot(131)\n",
        "    plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.5)\n",
        "    plt.title('PCA')\n",
        "\n",
        "    # t-SNE\n",
        "    plt.subplot(132)\n",
        "    plt.scatter(X_tsne[:, 0], X_tsne[:, 1], alpha=0.5)\n",
        "    plt.title('t-SNE')\n",
        "\n",
        "    # UMAP\n",
        "    plt.subplot(133)\n",
        "    plt.scatter(X_umap[:, 0], X_umap[:, 1], alpha=0.5)\n",
        "    plt.title('UMAP')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print PCA explained variance\n",
        "    print(\"PCA explained variance ratio:\", pca.explained_variance_ratio_)\n",
        "\n",
        "dimensionality_reduction_review()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFXkpdwZwfei"
      },
      "source": [
        "## 3. Anomaly Detection Review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q4g97kmwfei"
      },
      "source": [
        "def anomaly_detection_review():\n",
        "    # Generate data with anomalies\n",
        "    np.random.seed(42)\n",
        "    n_samples = 300\n",
        "\n",
        "    # Normal data\n",
        "    X_normal = np.random.normal(0, 1, (n_samples, 2))\n",
        "\n",
        "    # Add outliers\n",
        "    X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
        "    X = np.vstack([X_normal, X_outliers])\n",
        "\n",
        "    # Apply Isolation Forest\n",
        "    iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
        "    y_pred = iso_forest.fit_predict(X)\n",
        "\n",
        "    # Visualize results\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(X[y_pred == 1, 0], X[y_pred == 1, 1], label='Normal')\n",
        "    plt.scatter(X[y_pred == -1, 0], X[y_pred == -1, 1],\n",
        "                color='red', label='Anomaly')\n",
        "    plt.title('Anomaly Detection Results')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Print statistics\n",
        "    print(\"Number of detected anomalies:\", (y_pred == -1).sum())\n",
        "\n",
        "anomaly_detection_review()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr7TKXBowfei"
      },
      "source": [
        "## Week 4 Review Quiz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjgj6weWwfej"
      },
      "source": [
        "### Multiple Choice Questions\n",
        "\n",
        "1. Which clustering method requires specifying the number of clusters?\n",
        "   - a) DBSCAN\n",
        "   - b) K-means\n",
        "   - c) Hierarchical clustering\n",
        "   - d) Mean shift\n",
        "\n",
        "2. What is the main advantage of hierarchical clustering?\n",
        "   - a) Speed\n",
        "   - b) Dendrogram visualization\n",
        "   - c) Scalability\n",
        "   - d) Simplicity\n",
        "\n",
        "3. What does PCA maximize?\n",
        "   - a) Cluster separation\n",
        "   - b) Variance explained\n",
        "   - c) Distance preservation\n",
        "   - d) Data density\n",
        "\n",
        "4. Which method is best for visualizing high-dimensional data?\n",
        "   - a) PCA\n",
        "   - b) t-SNE\n",
        "   - c) K-means\n",
        "   - d) IsolationForest\n",
        "\n",
        "5. What is the main limitation of t-SNE?\n",
        "   - a) Linear only\n",
        "   - b) Slow computation\n",
        "   - c) No parameters\n",
        "   - d) Requires labels\n",
        "\n",
        "6. Which is NOT an application of clustering?\n",
        "   - a) Customer segmentation\n",
        "   - b) Image compression\n",
        "   - c) Time series prediction\n",
        "   - d) Document grouping\n",
        "\n",
        "7. What does UMAP preserve?\n",
        "   - a) Only local structure\n",
        "   - b) Only global structure\n",
        "   - c) Both local and global structure\n",
        "   - d) Neither\n",
        "\n",
        "8. Which method is most suitable for streaming data?\n",
        "   - a) t-SNE\n",
        "   - b) Hierarchical clustering\n",
        "   - c) Statistical methods\n",
        "   - d) UMAP\n",
        "\n",
        "9. What is the elbow method used for?\n",
        "   - a) Feature selection\n",
        "   - b) Optimal cluster number\n",
        "   - c) Anomaly detection\n",
        "   - d) Dimension selection\n",
        "\n",
        "10. Which is true about unsupervised learning?\n",
        "    - a) Requires labeled data\n",
        "    - b) Finds hidden patterns\n",
        "    - c) Always accurate\n",
        "    - d) Linear only\n",
        "\n",
        "Answers: 1-b, 2-b, 3-b, 4-b, 5-b, 6-c, 7-c, 8-c, 9-b, 10-b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cFi62jVwfej"
      },
      "source": [
        "## Week 4 Summary\n",
        "\n",
        "### Key Concepts Covered:\n",
        "1. Clustering algorithms and applications\n",
        "2. Dimensionality reduction techniques\n",
        "3. Anomaly detection methods\n",
        "4. Visualization approaches\n",
        "\n",
        "### Preparation for Week 5:\n",
        "- Review challenging concepts\n",
        "- Practice implementation\n",
        "- Prepare for deep learning\n",
        "- Review Python and libraries\n",
        "\n",
        "### Additional Resources:\n",
        "- Scikit-learn clustering guide: https://scikit-learn.org/stable/modules/clustering.html\n",
        "- UMAP documentation: https://umap-learn.readthedocs.io/\n",
        "- Anomaly detection tutorial: https://scikit-learn.org/stable/modules/outlier_detection.html"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}